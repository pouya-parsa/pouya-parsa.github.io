<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Pouya Parsa</title>
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="crossorigin"/>
    <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;family=Roboto:wght@300;400;500;700&amp;display=swap"/>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;family=Roboto:wght@300;400;500;700&amp;display=swap" media="print" onload="this.media='all'"/>
    <noscript>
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;family=Roboto:wght@300;400;500;700&amp;display=swap"/>
    </noscript>
    <link href="css/font-awesome/css/all.min.css?ver=1.2.1" rel="stylesheet">
    <link href="css/mdb.min.css?ver=1.2.1" rel="stylesheet">
    <link href="css/aos.css?ver=1.2.1" rel="stylesheet">
    <link href="css/main.css?ver=1.2.1" rel="stylesheet">
    <noscript>
      <style type="text/css">
        [data-aos] {
            opacity: 1 !important;
            transform: translate(0) scale(1) !important;
        }
      </style>
    </noscript>
  </head>
  <body class="bg-light" id="top">
    <header class="d-print-none">
      <div class="container text-center text-lg-left">
        <div class="pt-4 clearfix">
          <h1 class="site-title mb-0">Pouya Parsa</h1>
          <div class="site-nav"> 
            <nav role="navigation">
              <ul class="nav justify-content-center">
                <li class="nav-item"><a class="nav-link" href="#education" title="Education"><span class="menu-title">Education</span></a>
                </li>
                <li class="nav-item"><a class="nav-link" href="#experience" title="Experience"><span class="menu-title">Experience</span></a>
                </li>
                <li class="nav-item"><a class="nav-link" href="#projects" title="Projects"><span class="menu-title">Projects</span></a>
                </li>
                
              </ul>
            </nav>
          </div>
        </div>
      </div>
    </header>
    <div class="page-content">
      <div class="container">
<div class="resume-container">
  <div class="shadow-1-strong bg-white my-5" id="intro">
    <div class="bg-info text-white">
      <div class="cover bg-image"><img src="images/header-background.jpg"/>
        <div class="mask" style="background-color: rgba(0, 0, 0, 0.7);backdrop-filter: blur(2px);">
          <div class="text-center p-5">
            <div class="avatar p-1"><img class="img-thumbnail shadow-2-strong" src="images/avatar.jpg" width="160" height="160"/></div>
            <div class="header-bio mt-3">
              <div data-aos="zoom-in" data-aos-delay="0">
                <h2 class="h1">Pouya Parsa</h2>
                <p>Machine Learning</p>
              </div>
              <div class="header-social mb-3 d-print-none" data-aos="zoom-in" data-aos-delay="200">
                <nav role="navigation">
                  <ul class="nav justify-content-center">
                    <li class="nav-item"><a class="nav-link" href="https://twitter.com/pouyaparsa2" title="Twitter"><i class="fab fa-twitter"></i><span class="menu-title sr-only">Twitter</span></a>
                    </li>
                    <li class="nav-item"><a class="nav-link" href="#" title="Facebook"><i class="fab fa-facebook"></i><span class="menu-title sr-only">Facebook</span></a>
                    </li>
                    <li class="nav-item"><a class="nav-link" href="#" title="Instagram"><i class="fab fa-instagram"></i><span class="menu-title sr-only">Instagram</span></a>
                    </li>
                    <li class="nav-item"><a class="nav-link" href="https://github.com/pouya-parsa" title="Github"><i class="fab fa-github"></i><span class="menu-title sr-only">Github</span></a>
                    </li>
                  </ul>
                </nav>
              </div>
              <div class="d-print-none"><a class="btn btn-outline-light btn-lg shadow-sm mt-1 me-3" href="#experience" data-aos="fade-right" data-aos-delay="700">MY CV</a><a class="btn btn-info btn-lg shadow-sm mt-1" href="https://github.com/pouya-parsa" data-aos="fade-left" data-aos-delay="700">My Github</a></div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="shadow-1-strong bg-white my-5 p-5" id="education">
    <div class="education-section">
      <h2 class="h2 fw-light mb-4">Education</h2>
      <div class="timeline">
        <div class="timeline-card timeline-card-success" data-aos="fade-in" data-aos-delay="0">
          <div class="timeline-head px-4 pt-3">
            <div class="h5">B.Sc, Computer Science <span class="text-muted h6"> Amirkabir University of Technology </span>          </div>
          </div>
          <div class="timeline-body px-4 pb-4">
            <div class="text-muted text-small mb-3">2018 - 2023</div>
            <div><strong>GPA</strong>: 3.72/4</div>
            <div><strong>Thesis:</strong> Transformer-Based Model for Stock Price Prediction</div>
            <div><strong>Selected Courses:</strong> Artificial Intelligence (A+), Numerical Linear Algebra (A+) Design and Analysis of Algorithms
              (A), Linear Optimization (A), Probability-1 (A+)</div>
            <div><strong>Online Courses:</strong> CNNs for Visual Recognition (Stanford CS231n, online, audited), Generative Adversarial Networks
              (Coursera, online, certificate), Deep Reinforcement Learning (Udacity, online, audited), Introduction to NLP (IPM,
              certificate)</div>
          </div>
        </div>
        <div class="timeline-card timeline-card-success" data-aos="fade-in" data-aos-delay="200">
          <div class="timeline-head px-4 pt-3">
            <div class="h5">High School Diploma, Mathematics and Physics <span class="text-muted h6"> National Organization for Development of Exceptional Talents</span>          </div>
          </div>
          <div class="timeline-body px-4 pb-4">
            <div class="text-muted text-small mb-3">2014 - 2018</div>
            <div>GPA: 20/20</div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="shadow-1-strong bg-white my-5 p-5" id="experience">
    <div class="work-experience-section">
      <h2 class="h2 fw-light mb-4">Research Experience</h2>
      <div class="timeline">
        
        <div class="timeline-card timeline-card-info" data-aos="fade-in" data-aos-delay="0">
          <div class="timeline-head px-4 pt-3">
            <div class="h5">Computer Vision Researcher <span class="text-muted h6">at Zebracat.ai</span></div>
          </div>
          <div class="timeline-body px-4 pb-4">
            <div class="text-muted text-small mb-3">Sep 2022 - Present</div>
            <div>
              <ul>
                <li>Conducted a literature review on text-video retrieval models</li>
                <li>Trained shot transition detection models using dilated DCNN and frame similarity features</li>
                <li>Working on context-aware footage selection</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="timeline-card timeline-card-info" data-aos="fade-in" data-aos-delay="0">
          <div class="timeline-head px-4 pt-3">
            <div class="h5">Data Scientist Intern<span class="text-muted h6"> at MCI (Hamrahe aval)</span></div>
          </div>
          <div class="timeline-body px-4 pb-4">
            <div class="text-muted text-small mb-3">July 2022 - Sep 2022</div>
            <div>
              <ul>
                <li>I was a member of the R&D team responsible for developing recommender systems at MCI, Iran’s first
                  and largest mobile operator with over 67 million users</li>
                <li>Created a fault-tolerant Extract, Transform, Load (ETL) system data preparation</li>
                <li>Implemented a highly efficient collaborative filtering algorithm that provides suggested posts to a user
                  with response times of less than 10ms</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="timeline-card timeline-card-info" data-aos="fade-in" data-aos-delay="0">
          <div class="timeline-head px-4 pt-3">
            <div class="h5">Research Assistant<span class="text-muted h6"> at Novelties, Optimization & Redesigning of Cities (NORC) Lab</span></div>
          </div>
          <div class="timeline-body px-4 pb-4">
            <div class="text-muted text-small mb-3">Aug 2021 - Feb 2022</div>
            <div>
              <ul>
                <li>Advised by Prof. Mehdi Ghatee</li>
                <li>Utilized DeepLab and computer vision to create a robust model for detecting and recognizing
                  Iranian car plates with an accuracy greater than 87%</li>
                <li>Trained generative adversarial network (GAN)-based models to effectively eliminate fog artifacts from
                  images captured by transportation cameras.(<a href="https://github.com/pouya-parsa/dehaze_gan">Github</a>)</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="timeline-card timeline-card-info" data-aos="fade-in" data-aos-delay="0">
          <div class="timeline-head px-4 pt-3">
            <div class="h5">Research Assistant<span class="text-muted h6"> at Data Science Innovation Center</span></div>
          </div>
          <div class="timeline-body px-4 pb-4">
            <div class="text-muted text-small mb-3">Sep 2021 - March 2022</div>
            <div>
              <ul>
                <li>Advised by Prof. Mohammad Akbari</li>
                <li>Interpreted the latent space of GANs for semantic face editing</li>
                <li>Implemented the paper ’Progressive Growing of GANs for Improved Quality, Stability, and Variation’ as
                  a preliminary step towards using StyleGAN for semantic image editing (<a href="https://github.com/pouya-parsa/dehaze_gan">GitHub</a>)</li>
              </ul>
            </div>
          </div>
        </div>

        <div class="timeline-card timeline-card-info" data-aos="fade-in" data-aos-delay="0">
          <div class="timeline-head px-4 pt-3">
            <div class="h5">Machine Learning Intern University of Zurich<span class="text-muted h6"> at KrauthammerLab</span></div>
          </div>
          <div class="timeline-body px-4 pb-4">
            <div class="text-muted text-small mb-3">Aug 2021 - Feb 2022</div>
            <div>
              <ul>
                <li>Advised by Prof. Michael Krauthammer</li>
                <li>Contributed to the development of software interfaces for data ingestion, data pre-processing, machine
                  learning, visualization, and report generation</li>
              </ul>
            </div>
          </div>
        </div>
        
      
      </div>
    </div>
  </div>
  


  <div class="shadow-1-strong bg-white my-5 p-5" id="projects">
    <div class="education-section">
      <h2 class="h2 fw-light mb-4">Selected Projects</h2>
      
      <div class="container_projects">
        
        <div class="column">
          <div class="project">
            <img src="./images/projects/last_frame.png" alt="Progressive GANs">
            <p class="description">The mentioned model acts as a fundamental basis for various generative models like styleGAN, styleGAN2
              , and others. With the aim of enhancing my programming abilities and taking a preliminary step towards
              semantically editing GANs’ latent space, I personally implemented this research paper from scratch. The
              model underwent training for nearly two weeks on Google Colab. It progressively refines the learned details,
              which can be observed in the generated faces at both the early stages and the end of the training process.</p>
          </div>
        </div>

        <div class="column">
          <div class="project">
            <img src="./images/projects/AI_cup.png" alt="AI CUP">
            <p class="description">The AI CUP is an international competition held annually. In this competition, you have control over one
                player, while your competitor has coded the actions for Player 2. Player 1 represents our own player. By
                employing reinforcement learning, specifically a Deep Q Learning (DQN) agent, we achieved remarkable
                results thanks to the inherent scalar reward system in games. This system measures the player’s health,
                represented by a number ranging from 0 to 100.</p>
          </div>
        </div>

        <div class="column">
          <div class="project">
            <img src="./images/projects/vision_transformers.png" alt="Transformer-Based Stock Prediction">
            <p class="description">During my Bachelor’s thesis, I initially acquainted myself with the stock market and its specific terminology, including various indicators, indexes, and strategies. Subsequently, a two-step classifier was developed
              utilizing KNN and SVM, resulting in a notable 45% gain during back-testing in certain months of the year.
              To further explore possibilities, I ventured into incorporating the concept of vision transformers [2] into
              stock market prediction. Although this was an early exploration, it provided valuable insights and learning
              experiences. An overview of the overall design can be observed in the accompanying figure.</p>
          </div>
        </div>

        <div class="column">
          <div class="project">
            <img src="./images/projects/dehaze_in_one.png" alt="Dehazing by GANs">
            <p class="description">The project utilizes Generative Adversarial Networks (GANs) and incorporates a combination of perceptual
              loss and reconstruction loss to enhance convergence speed and image quality. The model has been trained on the O-Hazy dataset, which comprises a limited number (45) of groundlevel images. This dataset includes both hazy and non-hazy images from a specific scene. To overcome the
              hunger for data challenges faced by GANs, we employ an innovative data augmentation technique.</p>
          </div>
        </div>

        <div class="column">
          <div class="project">
            <img src="./images/projects/heart_rate.png" alt="Heart Rate Measurement From Video">
            <p class="description">My curiosity regarding the accuracy of non-contact heartbeat detection drives this project. Instead of relying on learning-based methods, I employ signal processing techniques
              to explore this topic. To evaluate the effectiveness of these techniques, I conduct experiments on the DEAP
              dataset. The process involves detecting the person’s face, extracting Regions of Interest (RoIs), and applying techniques such as detrending, hamming, and normalization. Heart rate extraction is then performed
              using various methods, including Fast Fourier Transform (FFT), Independent Component Analysis (ICA),
              and Principal Component Analysis (PCA). Among these methods, FFT appears to yield more promising
              results. The code for this project is available at this <a href="https://github.com/pouya-parsa/heart_rate_estimation">link</a></p>
          </div>
        </div>

        <div class="column">
          <div class="project">
            <img src="./images/projects/demo_pose_classificaiton.png" alt="Pose Classification">
            <p class="description">The project employs the R-CNN model, utilizing a ResNet-50-FPN backbone. Due to the pose estimation
              model’s tendency to produce false positives, a well-known object detection model called Yolo5 has been
              incorporated to improve predictions as a post-processing step. An online demo showcasing the application
              of pose classification in identifying hazardous positions of workers in construction sectors is accessible via
              the provided link.</p>
          </div>
        </div>

        <div class="column">
          <div class="project">
            <img src="./images/projects/large_language_models.png" alt="Software Requirement Eliciation">
            <p class="description">Expressing the desired functionalities of an application in a programmer-friendly language often poses a
              challenge for users. One approach to address this issue is to analyze and extract developer-oriented features
              from everyday communication platforms such as Twitter. In this demonstration, the process involves generating sample tweets related to a specific topic using a powerful language model like GPT3.5, followed by
              an attempt to articulate the features in more technical terms using GPT3.5 once again.</p>
          </div>
        </div>

      </div>
    </div>
  </div>

</div>
</div>
    </div>
    <footer class="pt-4 pb-4 text-muted text-center d-print-none">
      <div class="container">
        <div class="my-3">
          <div class="h4">Pouya Parsa</div>
        </div>
        <div class="text-small">
          <div class="mb-1">&copy; Pouya Parsa. All rights reserved.</div>
          <div>Design - <a href="https://templateflip.com/" target="_blank">TemplateFlip</a></div>
        </div>
      </div>
    </footer>
    <script src="scripts/mdb.min.js?ver=1.2.1"></script>
    <script src="scripts/aos.js?ver=1.2.1"></script>
    <script src="scripts/main.js?ver=1.2.1"></script>
  </body>
</html>